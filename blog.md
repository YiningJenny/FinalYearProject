## 25th June - Game Art design

I want to change the game background and other game assets. So I talk to my friend who is very good at painting. We decide to add more meaning to the arts design. The earliest Chinese hieroglyphics were found in Shang Dynasty, so we want to explore more related historic elements based on Shang dynasty. Here I list some of the components that match my project theme:

- Oracle bone script - This is the Chinese character that is oldest known from of Chinese writing.

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/ab747c95-4639-4a3d-b6a8-5dd4454cd917)

['Oracle bone script' (2023) Wikipedia. Available at: https://en.wikipedia.org/wiki/Oracle_bone_script]

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/4e51b593-9b78-4736-8dd6-7fd65084d4ce)

![BG_Black](https://github.com/YiningJenny/FinalYearProject/assets/119497753/3cb084cb-ebf1-4f0d-af15-311eb26aca64)

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/79abc1cc-8b81-4297-bc8d-6ddb44bee085)

---

- Ding (鼎) - Chinese bronze casting and pottery progressed during the Shang dynasty, and bronze was often used for objects of ceremonial significance rather than primarily for utilitarian purposes. The bronze Ding is one of the most important and iconic artefacts of the Shang Dynasty.

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/85238879-691a-4d76-90c4-a72f2d901c76)

Arguably, the most frequent, though also the most intriguing and mysterious, form of décor is the two eyed motif, often referred to as the taotie.

![Ding_(vessel),_China,_Shang_dynasty,_c _1500-1050_BCE,_HAA](https://github.com/YiningJenny/FinalYearProject/assets/119497753/dc2dc13f-5146-4aeb-a317-e865f93aa3b9)

['Shang dynasty' (2023) Wikipedia. Available at: https://en.wikipedia.org/wiki/Shang_dynasty]

So I also looked up into taotie decoration.

<img width="445" alt="image" src="https://github.com/YiningJenny/FinalYearProject/assets/119497753/6e3456ef-0824-49fe-b687-ae39dd19b4e0">

['Taotie pattern, ferocious beauty! ' (2020) Baidu Encyclopedia. Available at: https://wapbaike.baidu.com/tashuo/browse/content?id=5274c6261de9e8fb8a4e834f]

Additionally, I also find Ding characters interesting because its hieroglyphics looks like a cat. I want to introduce this word in Level 1 and make people feel confused. The evolution of Ding character:

![鼎](https://github.com/YiningJenny/FinalYearProject/assets/119497753/d07bf543-773e-444c-84be-0eeb4fc184d7)

['鼎' (2023) wiktionary. Available at: https://zh.wiktionary.org/zh/%E9%BC%8E]

---

- Sun and moon - Shang religious rituals featured divination and sacrifice. Shang Dynasty people observed astronomical signs and used them to calculate the dates of religious rituals and divination activities. Additionally, the astronomical and celestial records of the Shang Dynasty and the use of the stem-and-branch method of timekeeping are reflected in the oracle bone inscriptions. In this case, sun and moon must be important to Shang civilisation.

['Shang dynasty' (2023) Wikipedia. Available at: https://en.wikipedia.org/wiki/Shang_dynasty]

---

- The black bird - In mythology, the Shang dynasty believed themselves to be descendants of the black bird.

> The founding myth of the Shang dynasty is described by Sima Qian in the Annals of the Yin. In the text, a woman named Jiandi, who was the second wife of Emperor Ku, swallowed an egg dropped by a black bird (玄鳥) and subsequently gave birth miraculously to Xie – also appearing as Qi (契). Xie is said to have helped Yu the Great to control the Great Flood and for his service to have been granted a place called Shang as a fief.

['Shang dynasty' (2023) Wikipedia. Available at: https://en.wikipedia.org/wiki/Shang_dynasty]

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/659d259a-da10-49c1-8ab2-f9610035ca58)

['Sun Bird Gold Foil - Exhibition of cultural relics abroad is prohibited' (2015) Archeology Encyclopedia. Available at: https://baike.baidu.com/reference/4390795/f88apGq3NpDWad8B-gKntk1vJ_syo7ITFDs8ewI4RMSKTU3LyLX43u8axhMZlP8fPl8RU0fD4GmGh8h0b3p2IAl0QDg1brPuw6rPAs9nbi0ljneaLAESsi2CjEydlQc]  


## 26 June - Arduino Bluetooth module

I talked to Seamus and Matt and asked bluetooth, he gave me some suggestions and different sensors. I did some research for each of them. My plan was try them all during summer holiday.

From Seamus:

[Arduino Nano - blue tooth and wifi mode](https://www.mouser.co.uk/new/arduino/arduino-nano-every/?gclid=CjwKCAjwm4ukBhAuEiwA0zQxk8pebY_n3LenPcEZbYStm7q59uXyPWi-HoET1vFCzV8QOK2hvlKi3hoC4oYQAvD_BwE)

[Teesy - Cheap](https://coolcomponents.co.uk/collections/teensy?gclid=CjwKCAjwm4ukBhAuEiwA0zQxkyvt6xCOVzX7DUK9eDRKD7llE-vxhqkVarrxBbpTG-SXde3E6P9KYhoCLFQQAvD_BwE)

[ESP32 - bluetooth](https://docs.arduino.cc/hardware/nano-esp32)

From Matt:

[Arduino Nina Github library](https://github.com/sparkfun/SparkFun_Thing_Plus_NINA-B306/tree/main/Firmware/Examples)

[Nina documents](https://learn.sparkfun.com/tutorials/sparkfun-thing-plus---nina-b306-hookup-guide/all?print=1)

[How to use Bluetooth module with arduino (SPP-C and HC-05 tutorial)](https://youtu.be/Jn1WaDe-4tU?si=RXOUn4rWFQT4N5f4)

[HC-05 Bluetooth Module Interfacing with Arduino UNO](https://www.electronicwings.com/arduino/hc-05-bluetooth-module-interfacing-with-arduino-uno)

## 14 July - Tutorial with Mahalia
I talked to Mahalia about my project plan. I havn't totally decided what to do but generally base on last term's group work---[Legend of Hanzi](https://github.com/YiningJenny/A.C.E_Docs). I asked my groupmates, they don't mind about I keep developping this project.

My to-do list after talking to Mahalia:
- Assessment brief - help me explain my project to others 
- Ethics approval form - needed to be approved before data collection
- Time schedule - make a timetable
- Sketch - something like illustration with draft, also helps me explaining my project
- Technic list - Code, physical sensors, software…

## 12th Aug - Research on game machanics

__Some level design thoughts:__

- Players need to dance in the field character grid. The Chinese character is divided into different stroke parts, players step on the correct stroke, the corresponding part of the field character grid will light up, all step on the character is considered to be finished writing the word. Otherwise I can place different sensors in different positions according to the radicals, for example the radical armature (纟) is in the left part.
- Speaking practise - speech recognition
- Interactive projection
  
![field grid sketch](https://github.com/YiningJenny/FinalYearProject/assets/119497753/2ddfce30-7b5d-4a25-b8ec-a1dd83fe7310)

---

__Game scene arts design__

My game art designer finished the game background as I required:

Level 2 background:

![老蒋背景图](https://github.com/YiningJenny/FinalYearProject/assets/119497753/17e05bb7-4349-43de-b6a9-e21f6a3d8348)

## 17 - 18 August : flow chart and sketch diagram in Adobe AI
considered the entire flow of the game and how players interact with the screen. As a result of doing more in-depth research and thinking about the sensor and Unity interaction part of the game, I had to change some of the game mechanics, and the in-game UI.
- Level 3: __Chinese character formation in a grid using sections.__ Some Chinese characters are composed of identical elements, yet their placement varies. Some exhibit a left-right structure, while others feature a top-bottom configuration.“晖”&“晕”？Also, there are some characters are simply combined with same components like 木，林，森/又，双，叒，叕 (They're real Chinese characters, but they look like Legos.) .and how to interact? (The idea so far is to have three sensors on the top left and right for selecting text relative to the position on the screen. But i can only do "confirmation" like clicking instead of "selection" like computer mouse movement)  ___I need to check with Mahalia___
- Level 4: __horizontal board game.__ aiming to encourage players to practice speaking Chinese. players need to read specific Chinese sentences and control the game character to move smoothly. ___game map references some voice-activated games___
### physical prototype and game flow chart:

![Sketch_画板 1](https://github.com/YiningJenny/FinalYearProject/assets/119497753/b972b862-32c6-4234-bdbc-3966702479b5)
![Sketch-02](https://github.com/YiningJenny/FinalYearProject/assets/119497753/875b9f0b-e268-46cb-a33e-9a83c025a62d)

## 4th October - CCI symposium

- prototype of my new level:
  
![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/ef818751-abf4-4463-9aa3-c13e0675a38c)

- Audience testing:
  
![3d1b878bdee144ff4c64af7f7f74178](https://github.com/YiningJenny/FinalYearProject/assets/119497753/56bc6b70-0dfb-4eb4-aeaf-f89fce1a67b0)

- The second generation was not really related to language.
- The horizontal board games does not really make sense. (My prototype was not arduino based, so it was super simple to control by keyboard. The main character was designed by the meaning of person, that also not easy to tell.). If it's a voice controlled game, the level is fine. Maybe I can try endless platform running game, the arduino controlling would be much more easier with single induction.
- The grid word components combinition not really worked, they need someone to explain.
- make more depth of field. more lighting effects (leave it if I have more time)
- other thoughts about level design: dialogues with sentences that have several meanings, and the players can decide how the plot goes.
generally, all of them being more interested in Chinese learning, and the painting-based characters also make sense to them. Instead of serious language education, its more like a portal of Chinese learning.
- Generally, the audience prefer to be actively involved in the educational process and not simply be passive listeners and onlookers. Even though I was talking about game design elements which totally related to my practice part, almost all of them were scrolling. Maybe it's easier for people nowadays to accept digital information rather than purely text. (I will add it to my question list)

I also rescheduled my timetable:
![gantt chart](https://github.com/YiningJenny/FinalYearProject/assets/119497753/0566f498-01db-4763-bca3-00acaa468f27)

## 5th October - Toturial with Mahalia and Lieven
Mahalia's feedback: 
- The Level 1 character models are kind of blurred by the background. It lookd a little bit confusing, (maybe make people feel confused is my goal)but I'd better make the model more stand up from the background.
- We talked about game's core mechanics, she suggested me to talk to Lieven about the technical fundamentals.
- about dissertation: write pieces of paragraphs in daily, then I can organize them easily in the future.

Lieven's suggestion:
  - For speech recognition, I can try the following tutorials:
    - [google Speech-to-Text API](https://codelabs.developers.google.com/codelabs/cloud-speech-text-csharp#0)
    - [Microsoft Speech recognition engine class](https://learn.microsoft.com/en-us/dotnet/api/system.speech.recognition.speechrecognitionengine?view=netframework-4.8.1)
- For hand motion track, I can try:
  - camera
  - kinect (borrow one from CCI)
  - or leap motion
- For Arduino wireless, I can try:
  - [Bluetooth HC-05](https://www.deviceplus.com/arduino/how-to-control-an-arduino-from-a-windows-computer/)
Overall, the good news is that I don't need to use Arduino in the new levels, so need to worry the digital sending efficiency. 
## 9th Oct
Reschedualed my timetable. I realized that I cant really arrange till the last day. So I moved my plans up.
![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/892e3335-c871-4e9f-b249-ebac581fe7aa)
## 12th Oct - tutorial with Mahalia
I was kinda stuck on the core gameplay machanics. Mahalia suggestted me go back the original game goal and do a recap.
- Think about my target audience
  - My opinion was __'people who interested in language learing'__. Mahalia prefer to be open-minded and not that serious: language learning can be in another way, no class constraints. Compared with education, my project is more game based, so it's better for me to target my audience into __'people who interest in language'__
- To recap the story of my inspiration, tower babel. The first generation of the physical game was a brilliant way to convey the existence of language barriers. The second digital generation emphasises the importance of collaboration. Additionally, both generations of the game are co-operative multiplayer. However, due to time constraints, we removed all co-operative elements in the third generation. Now, I can reintroduce co-operation in the fourth generation because in the story of tower babel, those who tried to co-operate to build a tower in case of a second flood were punished by the gods. "collaboration" and "language" can be the two core machanics in my game. The mode of cooperation ccan be:
  - digital - two players chase each other in the game
  - physical - one player conduct and another operate
 I'm interested in both, I'll try make two playable versions and test them.
## 17th Oct - start Unity level design

- Sketch of the two game version and some of the Hanzi components that I want to use.

![第四关关卡设计草稿](https://github.com/YiningJenny/FinalYearProject/assets/119497753/9022e3b3-3b8a-460a-a9eb-1005f42448c6)

- another unfinished version of new level: As same as my workshop, I followed the method of disassembling the Hanzi into different parts and lowering the colour contrast of the fonts for the game background. Both on top and bottom of the screen, I used the 'spikes' word from Chinese hieroglyphics. Since Chinese hieroglyphics is more based on image, I except audience can recognize the meaning of the word by its shape. I also plan to apply more hieroglyphics to my game in this way.
  - In this level, two players need to work together to go through. Player1 needs to be the conductor, stand in front of the screen and give the order. Player2 needs to stand at back of the screen and follow the order. Their goal is to control the game character move left and right to survive as long as possible. Player1 shows the signal of "left" and "right", Player2 needs to speak "left" and "right" towards the microphone in Chinese mandarin.
- I hope players can practise speaking in this level.

![新版第四关](https://github.com/YiningJenny/FinalYearProject/assets/119497753/4c0745ea-d2fc-410b-bdb0-e8412fee8694)
![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/1ff41d16-759f-41c8-8795-b1a567dbdf72)

I will keep both of the two version for inviting people play my game, and do further adaptation.

- Hieroglyphics resources:

  ['朿', means spikes](https://m.dacidian.net/ziyuan_523A/)
  ,['朿'](https://www.sohu.com/a/340665654_673976)
  ,['朿'](https://en.wiktionary.org/wiki/%E6%9C%BF)
  
  ['矛', means spear](https://chardb.iis.sinica.edu.tw/evolution.jsp?cid=17440#)

## 19th Oct - Tutorial - Some bugs in the level design were discussed and identified, and solutions were devised.

It seems a bit wrong to include a co-operative section in the last level alone, maybe make the first two levels both in race mode, where players compete hard in the previous levels to determine the co-operative roles in the last level (e.g. the winner gets to be the conductor). This game mechanic could be a bit cheating and ANNOYING, as the effort they put in during the earlier parts has little to no substantial effect. Considering that the player who is the conductor might get bored (since he doesn't have to do anything but hold up signs), we considered letting the conductor control the player's jumping, but jumping isn't very necessary in this game, and might even hasten the player's death. The point of this design is this: tell the player that you can do this, but when they try it they will realise that it is a useless feature.

## 20 Oct

I modified the style of the game's characters based on the feedback I got from the workshop earlier. Allowing the characters to stand out more in the game scene.

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/be36a2cd-168f-498e-9744-7630cefb0bb3)


## 21th Oct
- assembly and test Arduino sensors and revise the previous code.
  ![cd4de8c54c1f73802d6bc65999d79c7](https://github.com/YiningJenny/FinalYearProject/assets/119497753/d3cba728-618c-4e0c-99b8-ac2b997b52e0)
- Continue Unity coding Level 4. (Finished the spike ball). I used the "spear" character in Chinese hieroglyphics as the spike ball sprite. Here's the code for _lineRenderer_ components in Unity:
  ```C#
    LineRenderer line;
    public Transform startPoint;
    public Transform endPoint;

    void Start()
    {
        line = GetComponent<LineRenderer>();
    }

    // Update is called once per frame
    void Update()
    {
        line.SetPosition(0, startPoint.position);
        line.SetPosition(1, endPoint.position);
    }
  ```
![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/f0245b73-7262-43f8-b64b-aced477c35da)


  
## 23th Oct

I realized that many people are very interested in the story behind the hieroglyphics and how they evoluted while talking with friends. I find the evolution of the hieroglyphics in game level 5

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/1275c944-d3a9-4e1f-b228-e99195572136)

['tripod' (2023) wiktionary. Available at: https://zh.wiktionary.org/zh/%E9%BC%8E]

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/f9fb30ed-53fc-4812-9fe6-fba81d74906c)

['Radical' (2023) wiktionary. Available at: https://en.wikipedia.org/wiki/Radical_196#Evolution]

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/0652bcc3-42e6-41e4-878e-e50e539420fb)

['聿' (2023) wiktionary. Available at: https://en.wiktionary.org/wiki/%E8%81%BF]

Props and narration & UI code:

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/0e4d2b5c-0ff3-4fc7-9667-94f22ebcaf0e)

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/0dfce457-ebb1-43eb-bfa4-76ab6327e5c6)

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/6388c9d0-8da5-48d8-a452-841c28849e2a)

```C#
    public GameObject yuDialog;
    public GameObject birdDialog;
    public GameObject dingDialog;

    public void CloseYuDialog()
    {
        yuDialog.SetActive(false);
        Time.timeScale = 1;
    }

    public void CloseBirdDialog()
    {
        birdDialog.SetActive(false);
        Time.timeScale = 1;
    }

    public void CloseDingDialog()
    {
        dingDialog.SetActive(false);
        Time.timeScale = 1;
    }
```

Game over interface:

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/1397afa8-2632-42ad-ad53-37db1c32600a)

---

![Animator](https://github.com/YiningJenny/FinalYearProject/assets/119497753/61446b35-b4ac-4fd8-b580-7b9ab3b68bef)

In order to realise the different animation effects of the game character switching between idling, running, jumping and dead, I created a float value _speed_, a boolen value _isOnGround_ and a trigger _dead_. 

---

I almost finish the main game mechanics for lavel 5. So I invited two of my friends to test it informal.

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/c2778146-a19e-4f33-b7d0-d0a2134112d0)

Their feedback:

- The speech level is far too difficult to pass through, because of the lack of game instruction, they don't know where to go in the game and how can they interact with the game.
- Its still very funny to control by speaking (both of them were willing to try more than twice), its so different from the traditional keyboard controlling. 

_My further plan as response: add text instrument in the game, and also try voice instrument._

## 24th Oct - Tutorial with Lieven

I talked to Lieven to figure out the __HC-05__ bluetooth module. I tried bluetooth moodule during summer vancancy but failed with the connection. We didn't totally succeed but fortunately I've got some progress after talking to Lieven.
The issues are listing below:

- I couldn't communicate from Arduino monitor to the HC-05 sensor.(It should be possible by online tutorial)
- My devices(including laptop and mobile phone) are unable to find the HC-05 through bluetooth.

The result was I successfully talk to HC-05 from Arduino Monitor and set up everything that we need for communication, including resetting the master-slave role command, setting memory command, resetting the password command. The circuit diagram is showing below:

![circuit diagram](https://github.com/YiningJenny/FinalYearProject/assets/119497753/600d83af-74fc-40e2-8ece-b68fd217f5dd)

I think the reason why I failed was because I didn't use specific resistors (1.1k and 3.3k). 

Arduino conponents and connections

![cee8c0b08a43e0a397f0bf4e85d81e3](https://github.com/YiningJenny/FinalYearProject/assets/119497753/d77d4750-dc96-4887-b73a-937646139a51)

The Arduino code:

```C++
#include <SoftwareSerial.h>
SoftwareSerial EEBlue(10, 11); // RX | TX
 
void setup()
{
  Serial.begin(9600);
  EEBlue.begin(38400);  //Baud Rate for command Mode. 
  Serial.println("Enter AT commands!");
}
 
void loop()
{
 
  // Feed any data from bluetooth to Terminal.
  if (EEBlue.available())
    Serial.write(EEBlue.read());
 
  // Feed all data from termial to bluetooth
  if (Serial.available())
    EEBlue.write(Serial.read());
}
```


__Useful online resources:__

- [Setting up Bluetooth HC-05 with Arduino](https://www.exploreembedded.com/wiki/Setting_up_Bluetooth_HC-05_with_Arduino)
- [HC-05 Documentation](https://www.rcscomponents.kiev.ua/datasheets/hc_hc-05-user-instructions-bluetooth.pdf)

## 26th - Toturial with Mahalia - my game is currently playable

- Level 2: can add some text or induction like "How the words evoluted"
- Level 5: the elements and introductions are very interesting, I can add more narrative in this level.

### next step:

- solder everything - measure the dark lab distance
- wireless - book Matt
- voice controlling
- gilding the lily: make Level 5 more beautiful - consider a long vertical map instead of endless. cover part of the scene and do some arts design to let player know the game scene is moving down.
- make my bow ROBUST and STREAMLINED - either wired or wireless. can use a smaller arduino board like Arduino NINA, then I can attach it to the bow

### measuring

- I went to the dark lab and sketched the game space

![dark lab reasure](https://github.com/YiningJenny/FinalYearProject/assets/119497753/3fa789d5-b464-4d2f-93e5-79018f211369)

### game arts design

I plan to make a new long vertical map and collage of representative artefacts from different eras as the new level. need to do more research. can refer to the Yangtze and Yellow River's shape cuz they are two main rivers in China. I talked to my friend Yang, she can help me do the map drawing.

![level draft](https://github.com/YiningJenny/FinalYearProject/assets/119497753/7f3e2e50-f0f5-4848-9acc-09c8ac5a8b95)

## 27th Oct - Soldering

[FRS Reference (circuit diagram and code)](https://www.circuits-diy.com/interfacing-force-sensing-resistor-fsr-with-arduino-uno/)

My final circuit diagram:

![99e4b3efdc68c4159827f10d81d8ad5](https://github.com/YiningJenny/FinalYearProject/assets/119497753/55635e7f-4f5f-492c-ada8-f07d643fc3e8)

Challenge I met and solution:
- I was worring that 4 force sensor being parallelled would lead to a very small electric current. So I tested and the reading from multimeter seems to be fine.
- There is a gap on the bread board between the two sides of the resistance. It is very obvious but easy to be ignored (I spent almost a hour to figure out why the force sensor is not sending digitals after soldering). At last I cut a hole in between and it worked.
- I didn't know that force sensor are not solderable, so I melt one...

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/408941d9-e82f-4923-bc9f-297ac02f5f67)

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/06d8e466-9b0a-4da9-8e1a-f63feafdfb18)

The core code communicate between Arduino and Unity:

- Arduino

```C++
#include <Wire.h>
#include "Adafruit_MPR121.h"
#include <Adafruit_Sensor.h>
#include <Adafruit_BNO055.h>
#include <utility/imumaths.h>

// touch sensor
#ifndef _BV
#define _BV(bit) (1 << (bit)) 
#endif

// orientation
#define BNO055_SAMPLERATE_DELAY_MS (100)
Adafruit_BNO055 bno = Adafruit_BNO055(55, 0x28, &Wire);

// force
#define FORCE_SENSOR_PIN A0 // the FSR and 10K pulldown are connected to A0

Adafruit_MPR121 cap = Adafruit_MPR121();
// touch sensor
uint16_t lasttouched = 0;
uint16_t currtouched = 0;

void setup() {
  Serial.begin(115200);
  
  // touch sensor
  // If tied to SDA its 0x5C and if SCL then 0x5D
  if (!cap.begin(0x5A)) {
    Serial.println("MPR121 not found, check wiring?");
    while (1);
  }
  Serial.println("MPR121 found!");

  // orientation
  if(!bno.begin())
  {
    Serial.print("Ooops, no BNO055 detected ... Check your wiring or I2C ADDR!");
    while(1);
  }
  bno.setExtCrystalUse(true);
}

void loop() {
  // pressure
  int analogReading = analogRead(FORCE_SENSOR_PIN);


  // orientation
    sensors_event_t event;
    bno.getEvent(&event);
    Serial.print("Vector3,");
    Serial.print(event.orientation.x, 4);
    Serial.print(",");
    Serial.print(event.orientation.y, 4);
    Serial.print(",");
    Serial.println(event.orientation.z, 4);
    Serial.print("Pressure:");
    Serial.println(analogReading);
    delay(50);
    
  // touch sesnsor
  currtouched = cap.touched();
  
  for (uint8_t i=0; i<12; i++) {
    // it if *is* touched and *wasnt* touched before, alert!
    if ((currtouched & _BV(i)) && !(lasttouched & _BV(i)) ) {
      //Serial.print(i); 
      Serial.println("Wire:1");//touched
    }
    // if it *was* touched and now *isnt*, alert!
    if (!(currtouched & _BV(i)) && (lasttouched & _BV(i)) ) {
      //Serial.print(i); 
      Serial.println("Wire:0");//released
    }
  }

  // reset our state
  lasttouched = currtouched;

  return; // important!! It works
    
  for (uint8_t i=0; i<12; i++) {
    Serial.print(cap.filteredData(i)); Serial.print("\t");
  }
  
  for (uint8_t i=0; i<12; i++) {
    Serial.print(cap.baselineData(i)); Serial.print("\t");
  }
  
  delay(50);
}
```

- Unity: receive data from Arduino (the way how I calculated light position is by using %, which makes sure the value always within 0 to 360 degree, this solves the issue from last iteration.)

```C#
 public void CheckArduino()
    {
        
        {
            string data = sp.ReadLine();// ReadByte();
            

            if (data.StartsWith("Vector3,"))
            {
                string[] splitData1 = data.Split(',');
                float xValue = float.Parse(splitData1[1]);
                float yValue = float.Parse(splitData1[2]);
                float zValue = float.Parse(splitData1[3]);
                lightPos = new Vector3(/*-1 **/ (((xValue + 180f) % 360f)/ 360f * 100f - 50f), (yValue + 45) / 2 + 10, -2.5f);
                // lightPos = new Vector3((xValue +180)%360), (yValue + 45) / 2 + 10, -2.5f);

                if (lightPos.x > 14.5) {

                    lightPos.x = 14.5f;
                }
                if (lightPos.x < -14.5)
                {
                    lightPos.x = -14.5f;
                }
                if (lightPos.y > 8.5)
                {

                    lightPos.y = 8.5f;
                }
                if(lightPos.y < -8.5)
                {
                    lightPos.y = -8.5f;
                }
                //print("lightPos"+lightPos);
            }

            else if (data.StartsWith("Wire:"))
            {
                string[] splitData1 = data.Split(':');
                int wireStatus = int.Parse(splitData1[1]);
                print("wireStatus:" + wireStatus);
                
                if (wireStatus == 0) // release
                {
                    currentTouch = false;
                    lastTouch = true;
                    //print("currentTouch:"+ currentTouch+ ",lastTouch:"+ lastTouch);
                }
                else if (wireStatus == 1) // touched
                {
                    currentTouch = true;
                    lastTouch = false;
                }
            }
        }
    }

 void CheckArduino()
    {
        string data = sp.ReadLine();
        // darts
        if (data.StartsWith("Pressure:"))
        {
            string[] splitData1 = data.Split(':');
            int pressureStatus = int.Parse(splitData1[1]);
            //print(pressureStatus);
            if (pressureStatus > 50)
            {
                boolPressureStatus = true;
            }
            else boolPressureStatus = false;
        }
    }
```

- Unity: use the data from Arduino and control point light position and dart triggering

```C#
public void LightPosition()
    {
        // rain
        if (lightController.lightPos.x > 1.469f &&
            lightController.lightPos.x < 6.131f &&
            lightController.lightPos.y < -5.572f &&
            lightController.lightPos.y > -8.06f)
        {
            rainPos = true;
            print("rainPos: " + rainPos);
        }

        else { 
            rainPos = false;
            print("rainPos: " + rainPos);
        }

        // sheep
        if (lightController.lightPos.x > 3.64f &&
            lightController.lightPos.x < 8.7f &&
            lightController.lightPos.y < 1.37f &&
            lightController.lightPos.y > -2.17f)
        {
            sheepPos = true;
            print("sheepPos: " + sheepPos);
        }
        else { 
            sheepPos = false;
            print("sheepPos: " + sheepPos);
        }

        // ding
        if (lightController.lightPos.x > -6.03f &&
            lightController.lightPos.x < -4.01f &&
            lightController.lightPos.y < -2.39f &&
            lightController.lightPos.y > -7.159f)
        {
            dingPos = true;
            print("dingPos: " + dingPos);
        }
        else
        {
            dingPos = false;
            print("dingPos: " + dingPos);
        }
    }
public void SelectTarget()
    {
        if (Input.GetMouseButtonDown(0) || boolPressureStatus == true)
        {
                //print("you are right");
                successDialog.SetActive(true);
                //Invoke("CloseSuccessDialog", 3f);//wait for 3s then call CloseSuccessDialog
                Invoke("NextLevel", 5f);
        }
    }
```
## 28th Oct - Speech recognition Test

### First trial

I firstly tried the speech to text recognition API. I followed the setup guidance linked below:

[Speech to text API with C#](https://codelabs.developers.google.com/codelabs/cloud-speech-text-csharp#1)

I replaced origin SpeechToTextApiDemo code with the code I show below: (with comments)

```C#
using Google.Cloud.Speech.V1;
using System;

namespace SpeechToTextApiDemo
{
    public class Program
    {
        public static void Main(string[] args)
        {
            var speech = SpeechClient.Create();
            var config = new RecognitionConfig
            {
                Encoding = RecognitionConfig.Types.AudioEncoding.Flac, // tells the API which type of audio encoding I'm using for the audio file. Flac is the encoding type for .raw files
                SampleRateHertz = 16000,
                LanguageCode = LanguageCodes.English.UnitedStates // set the language
            };
            var audio = RecognitionAudio.FromStorageUri("gs://cloud-samples-tests/speech/brooklyn.flac");         // I can pass the API either the uri of audio file in Cloud Storage or the local file path for the audio file. Here, I'm using a Cloud Storage uri.
            
            var response = speech.Recognize(config, audio);

            foreach (var result in response.Results)
            {
                foreach (var alternative in result.Alternatives)
                {
                    Console.WriteLine(alternative.Transcript);
                }
            }
        }
    }
}
```

Setup code and running output:

![TerminalScreenshot](https://github.com/YiningJenny/FinalYearProject/assets/119497753/9bb3e474-4d40-4cac-8127-24e64b7de3b2)

_This API has a powerful multi-language voice-to-text conversion feature. However, I think the functionality of this API is better suited to transcribing pre-recorded audio files to text, whereas I want the speech recognition functionality of the real thing interaction. So I don't think this API is suitable for my project._

### Second trial

I tried a Unity [Speech Recognition Package](https://github.com/huggingface/blog/blob/main/unity-api.md). But to use this package, the minimal Unity version should be 2020.3, I'm on 2019.3. So I can't use this either.

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/9296bb43-d285-4b95-adea-f12cb21393a3)

### Third trial

I found another [How to Add Voice Recognition to Your Game - Unity Tutorial](https://youtu.be/29vyEOgsW8s?si=k5xTsibSpG65xe7L) on YouTube. 

- Firstly, I need to enable my microphone in Unity. It's in player settings

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/4c911356-2b35-492e-8f6a-6ac5444e2fb4)

- Secondly, I used Speech library in Unity. I wanted a keyword to call functions, so I need a dictionary with string(keyword) and function(events)

- The full Speech recognize code:

```C#
using System.Collections;
using System.Collections.Generic;
using System.Linq;
using System;
using UnityEngine;
using UnityEngine.Windows.Speech;

public class VoiceMovement : MonoBehaviour
{
    private KeywordRecognizer keywordRecognizer;
    private Dictionary<string,Action> actions = new Dictionary<string, Action>();


    public float speed;

    public playerController_L4 playerController_L4;

    Rigidbody2D rb;
    Animator anim;

    void Start()
    {
        
        actions.Add("左", Left);
        actions.Add("left", Left);
        actions.Add("右", Right);
        actions.Add("right", Right);
        actions.Add("上", Up);


        keywordRecognizer = new KeywordRecognizer(actions.Keys.ToArray());
        keywordRecognizer.OnPhraseRecognized += RecognizedSpeech;
        keywordRecognizer.Start();

        rb = GetComponent<Rigidbody2D>();
        anim = GetComponent<Animator>();

    }

    private void RecognizedSpeech(PhraseRecognizedEventArgs speech)
    {
        Debug.Log(speech.text);
        actions[speech.text].Invoke();
    }

    private void Left()
    {
        transform.Translate(Vector3.left * speed * Time.deltaTime);
        transform.localScale = new Vector3(-1, 1, 1); // face direction
        anim.SetFloat("speed", Mathf.Abs(rb.velocity.x)); // running animation
    }

    private void Right()
    {
        transform.Translate(Vector3.right * speed * Time.deltaTime);
        transform.localScale = new Vector3(1, 1, 1); // face direction
        anim.SetFloat("speed", Mathf.Abs(rb.velocity.x)); // running animation
    }

    private void Up()
    {
        transform.Translate(Vector3.up * speed * Time.deltaTime);
    }
}

```

- [mechanics testing video](https://youtu.be/jzQ5CZeS-Wg?si=4zDvYW9h8yxAZu4I)
- [players testing video](https://youtu.be/Cd7srd1fWBs?si=7SgeRkTpOzcf6agv)

_The test results show a very serious delay in speech recognition, which seriously affects the player's game experience. I currently believe the delay is due to poor laptop radio, I will test again tomorrow with a wireless headset. Also, I think the game become much more difficult if controlled by speech, so I removed the spikes on buttom of the creeen._


## 29th Oct - Level 5 game background redesign

![f9934e1d6dcfe3b2e16bc1e4b19e05b](https://github.com/YiningJenny/FinalYearProject/assets/119497753/a6bfce68-ef18-46d5-ba03-6236a674755e)

I wanted to make a very long map for Level 5 with the combinition of Shang dynasty history. In Chinese literature, people like describing the timeline as a long river. Meanwhile, Yellow River is one of the most important and longest river in China. So I want to use Yellow River as a part of the game background. The green part of the draft is the block part that players can not go through. I plan to put some historical characters or antiques in the area to introduce the history of the Shang Dynasty.

## 31st Oct - Helloween

I am so proud of myself that i'm still working on Helloween :) The second image is I replaced the force sensor with more robust plugins and insulated them with glue gun.

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/d6fa6c6c-aaf7-45c8-b820-613bcb2f04e7)

- I attempted to get help from my friend who has good knowledge of medelling in c4d for the textual. We tried so many times always failed to import the model with textual from c4d to Unity. I asked in technic channel:

_Hi, does anyone know how to import 3d models with texture from c4d to Unity? I tried .fbx and .obj and .dae but all failed. The models in Unity are all plain without any textures. I'm on c4d OC texture_

<img width="265" alt="image" src="https://github.com/YiningJenny/FinalYearProject/assets/119497753/473b6071-c1fa-44fe-9794-d94d4e5ad467">

Finally I just try the 3d material in Unity and it worked so well...(I'm satisfied with the visual since its a unity 2d camera)

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/284e2fd4-4b9b-4039-8e38-152ded0067cf)

## 2nd Nov - Tutorial with Mahalia

I almost finished all of the programming in Unity, we tested the whole game together and get some insight feedback. (Basically all about UI and UE.)

- Level 1
  - The way how players interat with a bow is quite funny. Add more hieroglyphics to make the level more complicate, then they spend more time in this level.
  - Replace the voice induction into Chinese version.
- Level 5
  - Add some text inductions before the game start, then players know what to do.
  - Zoom out the story panel, to make the text easy to read.
  - Add a close button to the story panel, also add speech recognition to close the panel.

We also tried to figure out why the C4d texture didn't work in Unity. I tried to build a new metal material in Unity, and build a new _Ding_ word for my Level 1.

New material application and different version of Ding model:

<img width="1694" alt="image" src="https://github.com/YiningJenny/FinalYearProject/assets/119497753/62b985d0-3f49-4997-bbd4-c92996817c03">


How did I build it in blender: [Blender screen record](https://youtu.be/Kj2YJ270xbs)

Online reference: [Video tutorial resource](https://www.bilibili.com/video/BV1PV4y1Z73e/?spm_id_from=333.788&vd_source=eb2e63b03ba34f8273cf1f5dfca2021a)

## 6th Nov - Ding evolution animation

To show the evolution of 鼎(Ding) hieroglyphics, I chose four generations of the Ding character from different dynasties. To make the animation more smooth, I used [Runaway Interpolation](https://app.runwayml.com/ai-tools/frame-interpolation) to make the evolution animation. And then I used [CloudConvert](https://cloudconvert.com/mp4-to-gif), which allowed me to transfer .mp4 file into .gif file. That's because I need to edit every frame in Photoshop, and only [.gif](https://github.com/YiningJenny/FinalYearProject/blob/main/interpolation2.gif) file would be automatically splited into frames by Photoshop.

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/bc696e58-112e-40b1-91f3-54bb8ce3a2ef)

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/7fd5d7e6-8de5-473b-909a-843de870c24c)

![image](https://github.com/YiningJenny/FinalYearProject/blob/main/interpolation2.gif)

Add text and voice instructions to each level.

[.mp4 to .wav](https://www.veed.io/convert/mp4-to-wav?utm_source=google&utm_medium=cpc&utm_campaign=Search_PerfomanceMax_Youtube&utm_content=&utm_term=&gad_source=1&gclid=Cj0KCQjwtJKqBhCaARIsAN_yS_nBQzll02jmNVpQKsYX_ZV1Irf25AFf3ka-A6X-9RqHJInoshXINuoaAtspEALw_wcB)

## 7th Nov - 

The conductive bowstring broke again, so I found a super strong new one as replacement. But I found the wire and touch detective sensor wasn't very sensitive, either in Arduino IDE monitor or in Unity. I thought it was the new conductive wire not really conductive, but later we even tried copper wire, and it also didn't work. 

![微信图片_20231107153952](https://github.com/YiningJenny/FinalYearProject/assets/119497753/d8f70a5b-da2c-4529-8e42-1380c05855e1)

![微信图片_20231107154002](https://github.com/YiningJenny/FinalYearProject/assets/119497753/ac643554-eddc-4516-ad9b-0118962cc722)

So Me and Matt started considering if the _MPR121_ touch sensor broke. We tried to find some basic code and test the MPR121 alone.

__Testing code in Arduino__:
```C++
/*********************************************************
This is a library for the MPR121 12-channel Capacitive touch sensor

Designed specifically to work with the MPR121 Breakout in the Adafruit shop 
  ----> https://www.adafruit.com/products/

These sensors use I2C communicate, at least 2 pins are required 
to interface

Adafruit invests time and resources providing this open source code, 
please support Adafruit and open-source hardware by purchasing 
products from Adafruit!

Written by Limor Fried/Ladyada for Adafruit Industries.  
BSD license, all text above must be included in any redistribution
**********************************************************/

#include <Wire.h>
#include "Adafruit_MPR121.h"

#ifndef _BV
#define _BV(bit) (1 << (bit)) 
#endif

// You can have up to 4 on one i2c bus but one is enough for testing!
Adafruit_MPR121 cap = Adafruit_MPR121();

// Keeps track of the last pins touched
// so we know when buttons are 'released'
uint16_t lasttouched = 0;
uint16_t currtouched = 0;

void setup() {
  Serial.begin(9600);

  while (!Serial) { // needed to keep leonardo/micro from starting too fast!
    delay(10);
  }
  
  Serial.println("Adafruit MPR121 Capacitive Touch sensor test"); 
  
  // Default address is 0x5A, if tied to 3.3V its 0x5B
  // If tied to SDA its 0x5C and if SCL then 0x5D
  if (!cap.begin(0x5A)) {
    Serial.println("MPR121 not found, check wiring?");
    while (1);
  }
  Serial.println("MPR121 found!");
}

void loop() {
  // Get the currently touched pads
  currtouched = cap.touched();
  
  for (uint8_t i=0; i<12; i++) {
    // it if *is* touched and *wasnt* touched before, alert!
    if ((currtouched & _BV(i)) && !(lasttouched & _BV(i)) ) {
      Serial.print(i); Serial.println(" touched");
    }
    // if it *was* touched and now *isnt*, alert!
    if (!(currtouched & _BV(i)) && (lasttouched & _BV(i)) ) {
      Serial.print(i); Serial.println(" released");
    }
  }

  // reset our state
  lasttouched = currtouched;

  // comment out this line for detailed data from the sensor!
  return;
  
  // debugging info, what
  Serial.print("\t\t\t\t\t\t\t\t\t\t\t\t\t 0x"); Serial.println(cap.touched(), HEX);
  Serial.print("Filt: ");
  for (uint8_t i=0; i<12; i++) {
    Serial.print(cap.filteredData(i)); Serial.print("\t");
  }
  Serial.println();
  Serial.print("Base: ");
  for (uint8_t i=0; i<12; i++) {
    Serial.print(cap.baselineData(i)); Serial.print("\t");
  }
  Serial.println();
  
  // put a delay so it isn't overwhelming
  delay(100);
}
```

Testing result showed that the sensor actually worked very well. And that's when it happened, maybe it was because I used the wire for months, the ground wire even broke inside the plug of the Arduino board.

![微信图片_20231107154012](https://github.com/YiningJenny/FinalYearProject/assets/119497753/342134a5-695b-4341-bc6b-b3884fbe68f9)

I replaced the ground wire and everything went so smooth and perfect...

---

Then I continued finishing the user interface (UI) left. I redesigned the game start scene and add text instruments to each level.

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/795db5cc-9d44-42c9-abd3-8613e8a618bf)

![第一关UI截图](https://github.com/YiningJenny/FinalYearProject/assets/119497753/52f7dad9-90e2-4227-9e99-98034c908ed1)

![第二关UI截图](https://github.com/YiningJenny/FinalYearProject/assets/119497753/b33b9532-c475-4d47-888f-cf335dededdf)

![第五关UI截图](https://github.com/YiningJenny/FinalYearProject/assets/119497753/48e172fc-2599-4fe4-8282-a872756ac01d)


---

I found some Chinese triditional style music for my game background music:
- [Game start scene - 万神纪](https://www.bilibili.com/video/BV1wx41127TM/?spm_id_from=333.1007.top_right_bar_window_history.content.click&vd_source=eb2e63b03ba34f8273cf1f5dfca2021a)
- [Level 5 - 九九八十一](https://www.bilibili.com/video/BV1Ls411Q7iM/?share_source=copy_web&vd_source=f13076e590d71ce036a88a28071390d4)

## 8th-9th Nov - sodering and installation/Tutorial with Mahalia

![cac498417543f6f9492a38ff0c11e90](https://github.com/YiningJenny/FinalYearProject/assets/119497753/a0989b47-9b7a-4c5e-8a86-aab71d6faf55)

![43a61c8086c5906e89317b456b0df56](https://github.com/YiningJenny/FinalYearProject/assets/119497753/c251e3a1-b993-49df-86b1-e602511955b2)

I also updated my questionnair for tomorrow's filming and test - It's better to make every question clear and specific. Maybe the players prefer to answer "yes/no" question. But I can keep the detailed questions for those audience that wants to sit down and have a deep talk.

[Updated question sheet](https://github.com/YiningJenny/FinalYearProject/blob/main/QuestionSheet.docx)

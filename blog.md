## 25th June - Game Art design

I want to change the game background and other game assets. So I talk to my friend who is very good at painting. We decide to add more meaning to the arts design. The earliest Chinese hieroglyphics were found in Shang Dynasty, so we want to explore more related historic elements based on Shang dynasty. Here I list some of the components that match my project theme:

- Oracle bone script - This is the Chinese character that is oldest known form of Chinese writing.

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/ab747c95-4639-4a3d-b6a8-5dd4454cd917)

[Image from Wiki](https://en.wikipedia.org/wiki/Oracle_bone_script)

- Ding (鼎) - Chinese bronze casting and pottery progressed during the Shang dynasty, and bronze was often used for objects of ceremonial significance rather than primarily for utilitarian purposes. The bronze Ding is one of the most important and iconic artefacts of the Shang Dynasty.

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/85238879-691a-4d76-90c4-a72f2d901c76)

[Resources from Wiki](https://en.wikipedia.org/wiki/Shang_dynasty)

The evolution of Ding character:

![鼎](https://github.com/YiningJenny/FinalYearProject/assets/119497753/d07bf543-773e-444c-84be-0eeb4fc184d7)

[Resource from Wiki dictionary](https://zh.wiktionary.org/zh/%E9%BC%8E)

- Sun and moon - Shang religious rituals featured divination and sacrifice. Shang Dynasty people observed astronomical signs and used them to calculate the dates of religious rituals and divination activities. Additionally, the astronomical and celestial records of the Shang Dynasty and the use of the stem-and-branch method of timekeeping are reflected in the oracle bone inscriptions.

[Resources from Wiki](https://en.wikipedia.org/wiki/Shang_dynasty)

- The black bird - In mythology, the Shang dynasty believed themselves to be descendants of the black bird.

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/659d259a-da10-49c1-8ab2-f9610035ca58)

[Image from web](https://baike.baidu.com/reference/4390795/f88apGq3NpDWad8B-gKntk1vJ_syo7ITFDs8ewI4RMSKTU3LyLX43u8axhMZlP8fPl8RU0fD4GmGh8h0b3p2IAl0QDg1brPuw6rPAs9nbi0ljneaLAESsi2CjEydlQc)
  
[Resources from Wiki](https://en.wikipedia.org/wiki/Shang_dynasty)

## 26 June - Arduino Bluetooth module

I talked to Seamus and Matt and asked bluetooth, he gave me some suggestions and different sensors. I did some research for each of them. My plan was try them all during summer holiday.

From Seamus:

[Arduino Nano - blue tooth and wifi mode](https://www.mouser.co.uk/new/arduino/arduino-nano-every/?gclid=CjwKCAjwm4ukBhAuEiwA0zQxk8pebY_n3LenPcEZbYStm7q59uXyPWi-HoET1vFCzV8QOK2hvlKi3hoC4oYQAvD_BwE)

[Teesy - Cheap](https://coolcomponents.co.uk/collections/teensy?gclid=CjwKCAjwm4ukBhAuEiwA0zQxkyvt6xCOVzX7DUK9eDRKD7llE-vxhqkVarrxBbpTG-SXde3E6P9KYhoCLFQQAvD_BwE)

[ESP32 - bluetooth](https://docs.arduino.cc/hardware/nano-esp32)

From Matt:

[Arduino Nina Github library](https://github.com/sparkfun/SparkFun_Thing_Plus_NINA-B306/tree/main/Firmware/Examples)

[Nina documents](https://learn.sparkfun.com/tutorials/sparkfun-thing-plus---nina-b306-hookup-guide/all?print=1)

[How to use Bluetooth module with arduino (SPP-C and HC-05 tutorial)](https://youtu.be/Jn1WaDe-4tU?si=RXOUn4rWFQT4N5f4)

[HC-05 Bluetooth Module Interfacing with Arduino UNO](https://www.electronicwings.com/arduino/hc-05-bluetooth-module-interfacing-with-arduino-uno)

## 14 July - Tutorial with Mahalia
I talked to Mahalia about my project plan. I havn't totally decided what to do but generally base on last term's group work---[Legend of Hanzi](https://github.com/YiningJenny/A.C.E_Docs). I asked my groupmates, they don't mind about I keep developping this project.

My to-do list after talking to Mahalia:
- Assessment brief - help me explain my project to others 
- Ethics approval form - needed to be approved before data collection
- Time schedule - make a timetable
- Sketch - something like illustration with draft, also helps me explaining my project
- Technic list - Code, physical sensors, software…

## 12th Aug - Research on game machanics

__Some level design thoughts:__

- Players need to dance in the field character grid. The Chinese character is divided into different stroke parts, players step on the correct stroke, the corresponding part of the field character grid will light up, all step on the character is considered to be finished writing the word. Otherwise I can place different sensors in different positions according to the radicals, for example the radical armature (纟) is in the left part.
- Speaking practise - speech recognition
- Interactive projection
  
![field grid sketch](https://github.com/YiningJenny/FinalYearProject/assets/119497753/2ddfce30-7b5d-4a25-b8ec-a1dd83fe7310)

## 17 - 18 August : flow chart and sketch diagram in Adobe AI
considered the entire flow of the game and how players interact with the screen. As a result of doing more in-depth research and thinking about the sensor and Unity interaction part of the game, I had to change some of the game mechanics, and the in-game UI.
- Level 3: __Chinese character formation in a grid using sections.__ “森” or “晖”&“晕”？ and how to interact? (The idea so far is to have three sensors on the top left and right for selecting text relative to the position on the screen. But i can only do "confirmation" like clicking instead of "selection" like computer mouse movement)  ___I need to check with Mahalia___
- Level 4: __horizontal board game.__ aiming to encourage players to practice speaking Chinese. players need to read specific Chinese sentences and control the game character to move smoothly. ___game map references some voice-activated games___
### physical prototype and game flow chart:

![Sketch_画板 1](https://github.com/YiningJenny/FinalYearProject/assets/119497753/b972b862-32c6-4234-bdbc-3966702479b5)
![Sketch-02](https://github.com/YiningJenny/FinalYearProject/assets/119497753/875b9f0b-e268-46cb-a33e-9a83c025a62d)

## 4th October - CCI symposium

- prototype of my new level:
  
![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/ef818751-abf4-4463-9aa3-c13e0675a38c)

- Audience testing:
  
![3d1b878bdee144ff4c64af7f7f74178](https://github.com/YiningJenny/FinalYearProject/assets/119497753/56bc6b70-0dfb-4eb4-aeaf-f89fce1a67b0)

- The second generation was not really related to language.
- The horizontal board games does not really make sense. (My prototype was not arduino based, so it was super simple to control by keyboard. The main character was designed by the meaning of person, that also not easy to tell.). If it's a voice controlled game, the level is fine. Maybe I can try endless platform running game, the arduino controlling would be much more easier with single induction.
- The grid word components combinition not really worked, they need someone to explain.
- make more depth of field. more lighting effects (leave it if I have more time)
- other thoughts about level design: dialogues with sentences that have several meanings, and the players can decide how the plot goes.
generally, all of them being more interested in Chinese learning, and the painting-based characters also make sense to them. Instead of serious language education, its more like a portal of Chinese learning.
- Generally, the audience prefer to be actively involved in the educational process and not simply be passive listeners and onlookers. Even though I was talking about game design elements which totally related to my practice part, almost all of them were scrolling. Maybe it's easier for people nowadays to accept digital information rather than purely text. (I will add it to my question list)

I also rescheduled my timetable:
![gantt chart](https://github.com/YiningJenny/FinalYearProject/assets/119497753/0566f498-01db-4763-bca3-00acaa468f27)

## 5th October - Toturial with Mahalia and Lieven
Mahalia's feedback: 
- The Level 1 character models are kind of blurred by the background. It lookd a little bit confusing, (maybe make people feel confused is my goal)but I'd better make the model more stand up from the background.
- We talked about game's core mechanics, she suggested me to talk to Lieven about the technical fundamentals.
- about dissertation: write pieces of paragraphs in daily, then I can organize them easily in the future.

Lieven's suggestion:
  - For speech recognition, I can try the following tutorials:
    - [google Speech-to-Text API](https://codelabs.developers.google.com/codelabs/cloud-speech-text-csharp#0)
    - [Microsoft Speech recognition engine class](https://learn.microsoft.com/en-us/dotnet/api/system.speech.recognition.speechrecognitionengine?view=netframework-4.8.1)
- For hand motion track, I can try:
  - camera
  - kinect (borrow one from CCI)
  - or leap motion
- For Arduino wireless, I can try:
  - [Bluetooth HC-05](https://www.deviceplus.com/arduino/how-to-control-an-arduino-from-a-windows-computer/)
Overall, the good news is that I don't need to use Arduino in the new levels, so need to worry the digital sending efficiency. 
## 9th Oct
Reschedualed my timetable. I realized that I cant really arrange till the last day. So I moved my plans up.
![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/892e3335-c871-4e9f-b249-ebac581fe7aa)
## 12th Oct - tutorial with Mahalia
I was kinda stuck on the core gameplay machanics. Mahalia suggestted me go back the original game goal and do a recap.
- Think about my target audience
  - My opinion was __'people who interested in language learing'__. Mahalia prefer to be open-minded and not that serious: language learning can be in another way, no class constraints. Compared with education, my project is more game based, so it's better for me to target my audience into __'people who interest in language'__
- To recap the story of my inspiration, tower babel. The first generation of the physical game was a brilliant way to convey the existence of language barriers. The second digital generation emphasises the importance of collaboration. Additionally, both generations of the game are co-operative multiplayer. However, due to time constraints, we removed all co-operative elements in the third generation. Now, I can reintroduce co-operation in the fourth generation because in the story of tower babel, those who tried to co-operate to build a tower in case of a second flood were punished by the gods. "collaboration" and "language" can be the two core machanics in my game. The mode of cooperation ccan be:
  - digital - two players chase each other in the game
  - physical - one player conduct and another operate
 I'm interested in both, I'll try make two playable versions and test them.
## 17th Oct - start Unity level design

- Sketch of the two game version and some of the Hanzi components that I want to use.

![第四关关卡设计草稿](https://github.com/YiningJenny/FinalYearProject/assets/119497753/9022e3b3-3b8a-460a-a9eb-1005f42448c6)

- another unfinished version of new level: As same as my workshop, I followed the method of disassembling the Hanzi into different parts and lowering the colour contrast of the fonts for the game background. Both on top and bottom of the screen, I used the 'spikes' word from Chinese hieroglyphics. Since Chinese hieroglyphics is more based on image, I except audience can recognize the meaning of the word by its shape. I also plan to apply more hieroglyphics to my game in this way.
  - In this level, two players need to work together to go through. Player1 needs to be the conductor, stand in front of the screen and give the order. Player2 needs to stand at back of the screen and follow the order. Their goal is to control the game character move left and right to survive as long as possible. Player1 shows the signal of "left" and "right", Player2 needs to speak "left" and "right" towards the microphone in Chinese mandarin.
- I hope players can practise speaking in this level.

![新版第四关](https://github.com/YiningJenny/FinalYearProject/assets/119497753/4c0745ea-d2fc-410b-bdb0-e8412fee8694)
![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/1ff41d16-759f-41c8-8795-b1a567dbdf72)

I will keep both of the two version for inviting people play my game, and do further adaptation.

- Hieroglyphics resources:

  ['朿', means spikes](https://m.dacidian.net/ziyuan_523A/)
  ,['朿'](https://www.sohu.com/a/340665654_673976)
  ,['朿'](https://en.wiktionary.org/wiki/%E6%9C%BF)
  
  ['矛', means spear](https://chardb.iis.sinica.edu.tw/evolution.jsp?cid=17440#)

## 19th Oct - Tutorial
- 讨论并发现了关卡设计中的一些漏洞，并设计了解决方法。包括：
  - 单独在最后一关中加入合作环节似乎有些不妥，也许可以将前两关都做成竞赛模式，玩家在前面的关卡中努力竞争，来决定最后一关的合作角色（比如说赢的人可以当指挥）。这种游戏机制可能有些作弊和annoying，因为他们在前面部分付出的努力几乎没有实质性的作用。考虑到作为指挥的玩家可能会感到无聊（因为他除了举指示牌之外不用做任何事情），所以我们考虑让指挥家控制玩家跳跃，但是跳跃在这个游戏中并不是非常有必要，甚至可能会加速玩家死亡。这个设计的点在于：告诉玩家你可以这么做，但当他们尝试之后会发现这是个无用的功能。
## 21th Oct
- assembly and test Arduino sensors and revise the previous code.
  ![cd4de8c54c1f73802d6bc65999d79c7](https://github.com/YiningJenny/FinalYearProject/assets/119497753/d3cba728-618c-4e0c-99b8-ac2b997b52e0)
- Continue Unity coding Level 4. (Finished the spike ball)(在这里补充SpikeBall的代码和画线的组件和代码)
  
## 23th Oct

找了第五关文字对应的字形演变图

[Ding(鼎)](https://zh.wiktionary.org/zh/%E9%BC%8E)

[bird](https://en.wikipedia.org/wiki/Radical_196#Evolution)

[Yu(聿)](https://en.wiktionary.org/wiki/%E8%81%BF)


## 24th Oct - Tutorial with Lieven

I talked to Lieven to figure out the __HC-05__ bluetooth module. I tried bluetooth moodule during summer vancancy but failed with the connection. We didn't totally succeed but fortunately I've got some progress after talking to Lieven.
The issues are listing below:

- I couldn't communicate from Arduino monitor to the HC-05 sensor.(It should be possible by online tutorial)
- My devices(including laptop and mobile phone) are unable to find the HC-05 through bluetooth.

The result was I successfully talk to HC-05 from Arduino Monitor and set up everything that we need for communication, including resetting the master-slave role command, setting memory command, resetting the password command. The circuit diagram is showing below:

![circuit diagram](https://github.com/YiningJenny/FinalYearProject/assets/119497753/600d83af-74fc-40e2-8ece-b68fd217f5dd)

I think the reason why I failed was because I didn't use specific resistors (1.1k and 3.3k). 

The Arduino code:

```C++
#include <SoftwareSerial.h>
SoftwareSerial EEBlue(10, 11); // RX | TX
 
void setup()
{
  Serial.begin(9600);
  EEBlue.begin(38400);  //Baud Rate for command Mode. 
  Serial.println("Enter AT commands!");
}
 
void loop()
{
 
  // Feed any data from bluetooth to Terminal.
  if (EEBlue.available())
    Serial.write(EEBlue.read());
 
  // Feed all data from termial to bluetooth
  if (Serial.available())
    EEBlue.write(Serial.read());
}
```


__Useful online resources:__

- [Setting up Bluetooth HC-05 with Arduino](https://www.exploreembedded.com/wiki/Setting_up_Bluetooth_HC-05_with_Arduino)
- [HC-05 Documentation](https://www.rcscomponents.kiev.ua/datasheets/hc_hc-05-user-instructions-bluetooth.pdf)

## 26th - Toturial with Mahalia - my game is currently playable

- Level 2: can add some text or induction like "How the words evoluted"
- Level 5: the elements and introductions are very interesting, I can add more narrative in this level.

### next step:

- solder everything - measure the dark lab distance
- wireless - book Matt
- voice controlling
- gilding the lily: make Level 5 more beautiful - consider a long vertical map instead of endless. cover part of the scene and do some arts design to let player know the game scene is moving down.
- make my bow ROBUST and STREAMLINED - either wired or wireless. can use a smaller arduino board like Arduino NINA, then I can attach it to the bow

### measuring

- I went to the dark lab and sketched the game space

![dark lab reasure](https://github.com/YiningJenny/FinalYearProject/assets/119497753/3fa789d5-b464-4d2f-93e5-79018f211369)

### game arts design

I plan to make a new long vertical map and collage of representative artefacts from different eras as the new level. need to do more research. can refer to the Yangtze and Yellow River's shape cuz they are two main rivers in China. I talked to my friend Yang, she can help me do the map drawing.

![level draft](https://github.com/YiningJenny/FinalYearProject/assets/119497753/7f3e2e50-f0f5-4848-9acc-09c8ac5a8b95)

## 27th Oct - Soldering

[FRS Reference (circuit diagram and code)](https://www.circuits-diy.com/interfacing-force-sensing-resistor-fsr-with-arduino-uno/)

## 28th Oct - Speech recognition Test

### First trial

I firstly tried the speech to text recognition API. I followed the setup guidance linked below:

[Speech to text API with C#](https://codelabs.developers.google.com/codelabs/cloud-speech-text-csharp#1)

I replaced origin SpeechToTextApiDemo code with the code I show below: (with comments)

```C#
using Google.Cloud.Speech.V1;
using System;

namespace SpeechToTextApiDemo
{
    public class Program
    {
        public static void Main(string[] args)
        {
            var speech = SpeechClient.Create();
            var config = new RecognitionConfig
            {
                Encoding = RecognitionConfig.Types.AudioEncoding.Flac, // tells the API which type of audio encoding I'm using for the audio file. Flac is the encoding type for .raw files
                SampleRateHertz = 16000,
                LanguageCode = LanguageCodes.English.UnitedStates // set the language
            };
            var audio = RecognitionAudio.FromStorageUri("gs://cloud-samples-tests/speech/brooklyn.flac");         // I can pass the API either the uri of audio file in Cloud Storage or the local file path for the audio file. Here, I'm using a Cloud Storage uri.
            
            var response = speech.Recognize(config, audio);

            foreach (var result in response.Results)
            {
                foreach (var alternative in result.Alternatives)
                {
                    Console.WriteLine(alternative.Transcript);
                }
            }
        }
    }
}
```

Setup code and running output:

![TerminalScreenshot](https://github.com/YiningJenny/FinalYearProject/assets/119497753/9bb3e474-4d40-4cac-8127-24e64b7de3b2)

_This API has a powerful multi-language voice-to-text conversion feature. However, I think the functionality of this API is better suited to transcribing pre-recorded audio files to text, whereas I want the speech recognition functionality of the real thing interaction. So I don't think this API is suitable for my project._

### Second trial

I tried a Unity [Speech Recognition Package](https://github.com/huggingface/blog/blob/main/unity-api.md). But to use this package, the minimal Unity version should be 2020.3, I'm on 2019.3. So I can't use this either.

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/9296bb43-d285-4b95-adea-f12cb21393a3)

### Third trial

I found another [How to Add Voice Recognition to Your Game - Unity Tutorial](https://youtu.be/29vyEOgsW8s?si=k5xTsibSpG65xe7L) on YouTube. 

- Firstly, I need to enable my microphone in Unity. It's in player settings

![image](https://github.com/YiningJenny/FinalYearProject/assets/119497753/4c911356-2b35-492e-8f6a-6ac5444e2fb4)

- Secondly, I used Speech library in Unity. I wanted a keyword to call functions, so I need a dictionary with string(keyword) and function(events)

- The full Speech recognize code:

```C#
using System.Collections;
using System.Collections.Generic;
using System.Linq;
using System;
using UnityEngine;
using UnityEngine.Windows.Speech;

public class VoiceMovement : MonoBehaviour
{
    private KeywordRecognizer keywordRecognizer;
    private Dictionary<string,Action> actions = new Dictionary<string, Action>();


    public float speed;

    public playerController_L4 playerController_L4;

    Rigidbody2D rb;
    Animator anim;

    void Start()
    {
        
        actions.Add("左", Left);
        actions.Add("left", Left);
        actions.Add("右", Right);
        actions.Add("right", Right);
        actions.Add("上", Up);


        keywordRecognizer = new KeywordRecognizer(actions.Keys.ToArray());
        keywordRecognizer.OnPhraseRecognized += RecognizedSpeech;
        keywordRecognizer.Start();

        rb = GetComponent<Rigidbody2D>();
        anim = GetComponent<Animator>();

    }

    private void RecognizedSpeech(PhraseRecognizedEventArgs speech)
    {
        Debug.Log(speech.text);
        actions[speech.text].Invoke();
    }

    private void Left()
    {
        transform.Translate(Vector3.left * speed * Time.deltaTime);
        transform.localScale = new Vector3(-1, 1, 1); // face direction
        anim.SetFloat("speed", Mathf.Abs(rb.velocity.x)); // running animation
    }

    private void Right()
    {
        transform.Translate(Vector3.right * speed * Time.deltaTime);
        transform.localScale = new Vector3(1, 1, 1); // face direction
        anim.SetFloat("speed", Mathf.Abs(rb.velocity.x)); // running animation
    }

    private void Up()
    {
        transform.Translate(Vector3.up * speed * Time.deltaTime);
    }
}

```

- [mechanics testing video](https://youtu.be/jzQ5CZeS-Wg?si=4zDvYW9h8yxAZu4I)
- [players testing video](https://youtu.be/Cd7srd1fWBs?si=7SgeRkTpOzcf6agv)

_The test results show a very serious delay in speech recognition, which seriously affects the player's game experience. I currently believe the delay is due to poor laptop radio, I will test again tomorrow with a wireless headset._
